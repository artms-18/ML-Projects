{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comp_vision_project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzOxNjvYZLFJhd5oXCfDxo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artms-18/ML-Projects/blob/main/comp_vision_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNUUBcPTwh3J"
      },
      "source": [
        "# Image Classification using the CIFAR dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoWV0Doywq8o"
      },
      "source": [
        "## Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOK8w28Rune6"
      },
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "import pickle\n",
        "import tarfile\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, Add\n",
        "from keras.layers import Input, AveragePooling2D\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "r_vizG1dIodr",
        "outputId": "a67d488e-d461-4c16-f06e-141353605bba"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e5ca5e0a-473e-4a01-9397-0b7b5908b5b1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e5ca5e0a-473e-4a01-9397-0b7b5908b5b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cifar-10-python.tar.gz to cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch7S_id_wuOG"
      },
      "source": [
        "## Extracting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATnP8oZBuu8_"
      },
      "source": [
        "tar = tarfile.open(\"/content/cifar-10-python.tar.gz\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OG_UKWmuxw3"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "**Note** \n",
        "\n",
        "The CIFAR dataset contains images in batches to speed up training, additionally, they are formatted in the shape of a 10000x3072 numpy array (rgb). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz5WGWdpzl9h"
      },
      "source": [
        "def get_batches(file):\n",
        "  batches = []\n",
        "  for dirName, subdirList, fileList in os.walk(file):\n",
        "    #print('Found directory: %s' % dirName)\n",
        "    for fname in fileList:\n",
        "      if \"data_batch_\" in fname:\n",
        "        #print('\\t%s' % fname)\n",
        "        batches.append(str(fname))\n",
        "  return batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1cbhATv0Y_3"
      },
      "source": [
        "batches = get_batches(\"/content/cifar-10-batches-py\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iro8O1cPyLpf"
      },
      "source": [
        "def unpickle(file):\n",
        "  with open(file, 'rb') as fo:\n",
        "    dict = pickle.load(fo, encoding = 'bytes')\n",
        "  return dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heSE56hCVoKH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A1YnoavyBGB"
      },
      "source": [
        "all_data = []\n",
        "for batch in batches:\n",
        "  all_data.append(unpickle(\"/content/cifar-10-batches-py\" + \"/\" + batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozHdN0vSyGGe"
      },
      "source": [
        "def shape(batch):\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  Reshapes and transposes images into correct shape for training\n",
        "\n",
        "  Args: a dict for a batch of images with the shape (10000, 3072)\n",
        "  Returns: a tuple containing (preprocessed images, labels)\n",
        "\n",
        "  \"\"\"\n",
        "  images = batch[b'data'].reshape(len(batch[b'data']), 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "  labels = batch[b'labels']\n",
        "\n",
        "  return images, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GiS1huu1dDT"
      },
      "source": [
        "preprocessed = []\n",
        "for batch in all_data:\n",
        "  preprocessed.append(shape(batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9mbB9ki6UpL"
      },
      "source": [
        "## Visualizing an image from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "swquOU-e7gyc",
        "outputId": "da13994b-67dc-486d-d950-21e8190c9407"
      },
      "source": [
        "#get random image\n",
        "\n",
        "import random\n",
        "random_index = random.randint(0, len(preprocessed[0][0]))\n",
        "random_index\n",
        "\n",
        "plt.figure(figsize = (8,12))\n",
        "plt.imshow(preprocessed[0][0][random_index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff7be7f7c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6xSM8mX78gO"
      },
      "source": [
        "## More Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSJw3YqW9JGf"
      },
      "source": [
        "# normalize each image between values of 0-1 using the z-score normalization equation\n",
        "\n",
        "def normalize(img):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args: a numpy array with pixel values ranging from 0-255\n",
        "  Returns: a normalized numpy array with values ranging between 0-1\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  min = np.min(img)\n",
        "  max = np.max(img)\n",
        "  normalized = (img - min) / (max - min) \n",
        "\n",
        "  normalized = tf.cast(normalized, dtype = tf.float32)\n",
        "\n",
        "  return normalized\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du8tIc5eJqf0"
      },
      "source": [
        "# labels are integers ranging from 0-9 corresponding to indexes for a particular label in label dict\n",
        "\n",
        "def one_hot_encode(label):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args: an integer label ranging from 0-9\n",
        "\n",
        "  Returns: a one-hot encoded version of the label with a '1' \n",
        "           at the corresponding index (e.g the label '3' will be one-hot-encoded\n",
        "           into a tensor of shape (1,10) with zeroes at every index except the 3rd)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  encoded = tf.one_hot(label, 10)\n",
        "  return encoded\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRFr9Bjd_hYe"
      },
      "source": [
        "def preprocess(filename):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args: a filename containing a batch directory as well as a sub directory of batches\n",
        "\n",
        "  Returns: a preprocessed dataset in the form of of normalized images (batch size, 32, 32, 3) and \n",
        "           one-hot-encoded labels of shape (1, 10).\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  batches = get_batches(filename)\n",
        "  all_data = []\n",
        "\n",
        "  for batch in batches:\n",
        "    all_data.append(unpickle(\"/content/cifar-10-batches-py\"+\"/\"+batch))\n",
        "\n",
        "  data = []\n",
        "\n",
        "    \n",
        "  for i, batch in enumerate(all_data):\n",
        "    \n",
        "    images, labels = shape(batch)\n",
        "    images = np.array([normalize(x) for x in images])\n",
        "    labels = [one_hot_encode(x) for x in labels]\n",
        "    data.append((images,labels))\n",
        "\n",
        "  return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhEfLCPlWdSR"
      },
      "source": [
        "data = preprocess(\"/content/cifar-10-batches-py\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKZbBaUjamc_"
      },
      "source": [
        "Right now, batches are in separate lists. To make training faster we want to convert the\n",
        "data to a tensorflow dataset and have it prefetched. After that we can rebatch the dataset into batches of 10000 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuREtZEVdypA"
      },
      "source": [
        "def one_list(list):\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  Args: a list containing a different batch at each index\n",
        "\n",
        "  Returns: 2 lists: Images and Labels\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for i, batch in enumerate(list):\n",
        "    for image in batch[0]:\n",
        "      images.append(image)\n",
        "    for label in batch[1]:\n",
        "      labels.append(label)\n",
        "\n",
        "  return images, labels\n",
        "\n",
        "def convert_to_dataset(data):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args: a list with sublists of batches. \n",
        "        batch[0] = images\n",
        "        batch[1] = label\n",
        "\n",
        "  Returns: a prefetched and batched tensorflow dataset\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  if len(data)> 1:\n",
        "    images, labels = one_list(data)\n",
        "  else:\n",
        "    images = data[0][0]\n",
        "    labels = data[0][1]\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "  dataset.batch(10000).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ9xXOQvfVL-"
      },
      "source": [
        "temp_images, labels = one_list(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYtrsr5FfnVs"
      },
      "source": [
        "train_dataset = convert_to_dataset(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcvp4ubkhOs9",
        "outputId": "74a63892-2cf1-4adc-807a-addcdbea4225"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((32, 32, 3), (10,)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL-27OdwNN6t"
      },
      "source": [
        "## My Steps\n",
        "\n",
        "1. Build a basic residual block function that will compute convolutions and add the resultant tensor with that of the original\n",
        "2. Build an identity block function that will "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhSgy_W5k_CL"
      },
      "source": [
        "# First define the identity block, where the dimension des not change, but the depth does.\n",
        "# Following the stucture of the ResNet50 model\n",
        "\n",
        "def identity(input, filters):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args:  \n",
        "    input: the input passed from a previous layer (using the tensorflow functional API)\n",
        "    filters: a tuple containing the respective number of filters being applied in the convolutions\n",
        "\n",
        "  Returns: an output 'x' of which will be passed to another layers within the model\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  skip = input\n",
        "  filter_1, filter_2 = filters\n",
        "\n",
        "  #first block\n",
        "  x = Conv2D(filter1, kernel_size = (1,1), strides = (1,1), padding = 'valid', kernel_regularizer = l2(0.001))(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #second block (size is kept the same with padding = 'same')\n",
        "  x = Conv2D(filter1, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_regularizer = l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #third block \n",
        "  x = Conv2D(filter2, kernel_size= (1,1), strides = (1,1), padding = 'valid', kernel_regularizer = l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  #add the input\n",
        "  x = Add()([x, skip])\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  return x\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC5V2ccUrtXB"
      },
      "source": [
        "def res_conv(input, strides, filters):\n",
        "\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    \n",
        "    input: the input passed from a previous layer\n",
        "    strides: how far the filter moves before being applied again \n",
        "    filters: a tuple containing the number of conv filters being applied to the input\n",
        "  \n",
        "\n",
        "  Returns:\n",
        "\n",
        "    an output with reduced dimensionality of the input shape /2 (following the ResNet50 structure)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  skip = input\n",
        "  filter1, filter2 = filters\n",
        "\n",
        "  #first block\n",
        "  x = Conv2D(filter1, kernel_size = (1,1), strides = (strides, strides), padding = 'valid', kernel_regularizer=l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #second block\n",
        "  x = Conv2D(filter1, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_regularizer= l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #third block\n",
        "  x = Conv2D(filter2, kernel_size = (1,1), strides = (1,1), padding = 'valid', kernel_regularizer = l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  \n",
        "  #converting the input tensor to match the dimensionality of the newly changed x (due to changing the strides)\n",
        "  skip = Conv2D(filter2, kernel_size = (1,1), strides = (strides, strides), padding = 'valid', kernel_regularizer = l2(0.001))(x)\n",
        "  skip = BatchNormalization()(skip)\n",
        "\n",
        "  #add\n",
        "  x = Add()([x, skip])\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM2xtrRarxX5"
      },
      "source": [
        "def resnet50():\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args: None\n",
        "\n",
        "  Returns: the ResNet50 tensorflow model\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  input_image = Input(shape = (image.shape[1], image.shape[2], image.shape[3])) #the way images in CIFAR dataset are stuctured\n",
        "  x = ZeroPadding2D(padding = (3,3))(input_image) #to preserve original input size\n",
        "\n",
        "  #step 1: maxpooling (refer to model summary of ResNet50)\n",
        "\n",
        "  x = Conv2D(64, kernel_size = (7,7), strides = (2,2))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "  x = MaxPooling2D((3,3), strides = (2,2))(x)\n",
        "\n",
        "  #step 2:\n",
        "\n",
        "  x = res_conv(x, strides = 1, filters = (64, 256))\n",
        "  x = identitiy(x, filters=(64, 256))\n",
        "  x = identity(x, filters = (64,256))\n",
        "\n",
        "  #step 3:\n",
        "\n",
        "  x = res_conv(x, strides = 2, filters = (128, 512))\n",
        "  x = identity(x, filters = (128, 512))\n",
        "  x = identity(x, filters = (128, 512))\n",
        "  x = identity(x, filters = (128, 512))\n",
        "\n",
        "  #step 4\n",
        "\n",
        "  x = res_conv(x, strides = 2, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "\n",
        "  #step 5\n",
        "\n",
        "  x = res_conv(x, strides = 2, filters = (512, 2048))\n",
        "  x = identity(x, filters = (512, 2048))\n",
        "  x = identity(x, filters = (512, 2048))\n",
        "\n",
        "  #model concludes with average pooling and dense connection\n",
        "\n",
        "  x = AveragePooling2D((2,2), padding = 'same')(x)\n",
        "\n",
        "  #add a flatten layer as dense required this input shape\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(10, activation = 'softmax', kernal_initializer = 'he normal')(x)\n",
        "\n",
        "  model = Model(inputs = image, outputs = x, name = 'Resnet50')\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}