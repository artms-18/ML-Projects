{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comp_vision_project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMPPLULXyJysYe3qvGz2rKO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artms-18/ML-Projects/blob/main/comp_vision_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNUUBcPTwh3J"
      },
      "source": [
        "# Image Classification using the CIFAR dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoWV0Doywq8o"
      },
      "source": [
        "## Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOK8w28Rune6"
      },
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "import pickle\n",
        "import tarfile\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, Add\n",
        "from keras.layers import Input, AveragePooling2D\n",
        "from keras.models import Model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "r_vizG1dIodr",
        "outputId": "76589b60-33d6-42ac-febe-83c98a6863f4"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4657e070-7418-435a-b2e7-546c1383cc13\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4657e070-7418-435a-b2e7-546c1383cc13\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cifar-10-python.tar.gz to cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch7S_id_wuOG"
      },
      "source": [
        "## Extracting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATnP8oZBuu8_"
      },
      "source": [
        "tar = tarfile.open(\"/content/cifar-10-python.tar.gz\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OG_UKWmuxw3"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "**Note** \n",
        "\n",
        "The CIFAR dataset contains images in batches to speed up training, additionally, they are formatted in the shape of a 10000x3072 numpy array (rgb). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz5WGWdpzl9h"
      },
      "source": [
        "def get_batches(file):\n",
        "  batches = []\n",
        "  test = []\n",
        "  for dirName, subdirList, fileList in os.walk(file):\n",
        "    #print('Found directory: %s' % dirName)\n",
        "    for fname in fileList:\n",
        "      if \"data_batch_\" in fname:\n",
        "        #print('\\t%s' % fname)\n",
        "        batches.append(str(fname))\n",
        "      elif \"test_batch\" in fname:\n",
        "        batches.append(str(fname))\n",
        "  return batches"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1cbhATv0Y_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98a9ea6-7343-4790-dff3-fad87bd50881"
      },
      "source": [
        "batches = get_batches(\"/content/cifar-10-batches-py\")\n",
        "print(batches)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data_batch_5', 'data_batch_4', 'data_batch_1', 'data_batch_2', 'data_batch_3', 'test_batch']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iro8O1cPyLpf"
      },
      "source": [
        "def unpickle(file):\n",
        "  with open(file, 'rb') as fo:\n",
        "    dict = pickle.load(fo, encoding = 'bytes')\n",
        "  return dict"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heSE56hCVoKH"
      },
      "source": [
        ""
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A1YnoavyBGB"
      },
      "source": [
        "all_data = []\n",
        "for batch in batches:\n",
        "  all_data.append(unpickle(\"/content/cifar-10-batches-py\" + \"/\" + batch))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozHdN0vSyGGe"
      },
      "source": [
        "def shape(batch):\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  Reshapes and transposes images into correct shape for training\n",
        "\n",
        "  Args: a dict for a batch of images with the shape (10000, 3072)\n",
        "  Returns: a tuple containing (preprocessed images, labels)\n",
        "\n",
        "  \"\"\"\n",
        "  images = batch[b'data'].reshape(len(batch[b'data']), 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "  labels = batch[b'labels']\n",
        "\n",
        "  return images, labels"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GiS1huu1dDT"
      },
      "source": [
        "preprocessed = []\n",
        "for batch in all_data:\n",
        "  preprocessed.append(shape(batch))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9mbB9ki6UpL"
      },
      "source": [
        "## Visualizing an image from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "swquOU-e7gyc",
        "outputId": "1ada6627-5d17-4570-d029-dc35c5b993f2"
      },
      "source": [
        "#get random image\n",
        "\n",
        "import random\n",
        "random_index = random.randint(0, len(preprocessed[0][0]))\n",
        "random_index\n",
        "\n",
        "plt.figure(figsize = (8,12))\n",
        "plt.imshow(preprocessed[0][0][random_index])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fed65c0c590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHdCAYAAADFMKrmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dW4xd53ne8efd58OcKZKiSMqWZMWKaidyyhoJEhRuUgeOb2yjQRADDVQggHIRAw6aixq5iVO0QFrk0JvChQIbUQAnjhE7sREYaQTDgGOgkE3bsixbtnWieBDFEck5z+zj+nrBrZa1OCTXQ8587Mz/Bwic2TOP1trrsJ9ZM3vvN1JKAgAAu6uSewUAANiPKGAAADKggAEAyIACBgAgAwoYAIAMaru5sFa7maanu6VzlUpYy6tUvJ8vKtWqlYvwcs1G28qlorByYf7YNej3rNxoNPAWmLz7l9LIyoXMVwSYG3Q89u7fYDgunSnMu+a+SqLZbHi5VtPKmYeKRiPvWJH3kCT3RSfuuV6peAu0l2c+drobdDDw9p9591Sv10tn1tc21Ov1r3kHd7WAp6e7+tC/eW/pXHfKOyk7nY6V687MWLlqfcrK3X/vO63csNe3cs2Gd9CeeuVHVu7ihbNWrlKsWblR/7KVq4b5A03NOz4vr2xZufOLq6Uzmz3vgXhgFtT9b7vXyr3twfut3LDv3b/XFi9ZOXk/X6gYerlhb8PKuef6eOAdm1PdWStXmFV0+sxFK7e56Z3rR48eLZ35wuf/cduv8StoAAAyoIABAMjglgo4It4XET+MiBci4mO3a6UAANjr7AKOK884+u+SfkXSw5I+HBEP364VAwBgL7uVK+B3S3ohpfRSSmkg6TOSPnB7VgsAgL3tVgr4qKQzV31+dnLb/yMiHouIkxFxsrflPWsXAIC9ZsefhJVSejyldCKldKLV9l6uAQDAXnMrBXxO0vGrPj82uQ0AANzArRTwNyQ9GBH3RURD0q9L+uLtWS0AAPY2+52wUkqjiPiIpP8pqSrpUyml7922NQMAYA+7pbeiTCl9SdKXbtO6AACwb/BOWAAAZLCrwxiK8Vjra+XfSH75svdzwk881LJy7aY50aPiLe+uA94bmF9a9J7z9sor3l8Kzr7sDWOoFt4bwndb3oSUes3bf4U5nSiNyk8nkqR2s/xkFUmqt8rfv1rNu2/NivcQ0Wx7UwcuLL5s5cZDb1tefH3Jyo3Cu3/Dvjnwo/AeA9sNb2pEjL0JZtMdLze34N2/C4veY8sLz1+wcsNh+f0+GGy/TbgCBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMKGAAADKggAEAyIACBgAgg12dhtRoNHT/W4+Vzp07c9la3uqSl+t0mlbunqNvsXJrq4tW7kc/+raVO336OSt3z4I3tanb6Fq5VHiTVba2vEk1q8vLVm5oTkOKVsfKJZXfLmGe6Qfu8tYxqptWbqu/ZeWWL3n7fHnZW56q3lSjuZl5K3dw7rCVO37PfVbu4msXrdzKpTNWrkjJyk21vO3ZbvSs3KWL5TtlNNp+YhNXwAAAZEABAwCQAQUMAEAGFDAAABlQwAAAZEABAwCQAQUMAEAGFDAAABlQwAAAZEABAwCQAQUMAEAGFDAAABlQwAAAZLCr05AqFanVKj/1YnrGW5473aZWb1m5Vvs1K3f6lDedaGPtkpWL5E1yScX2Uz2uZ+wNC1KlWrVyNXP6Ur3dt3Iae5NVUjWsXN04a9sd75g+cveClWs0rJguX/KmE1Uq3jHdqHvTnqo1b9/dfeiQlbvv+P1W7sDsESs33/H2+w9/aJ5DQ2//vfXYcSs36E1ZuWee8ybQbYcrYAAAMqCAAQDIgAIGACADChgAgAwoYAAAMqCAAQDIgAIGACADChgAgAwoYAAAMqCAAQDIgAIGACADChgAgAwoYAAAMtjVaUjDUV8XFk+XztUb3lScrd6mlXvl1Bkrd2lpycp1O95uSCNv8khF3iSXwdCbhjQcDKxcd8obgzUObxRPNNtWzj2J+kNvu7Sb5Zd4/NhRa1mzC942Wbx0wcqtrW5YORXeek53vclZkjfiqxp1K9fb8qZEvbp+1sptra5YuVD5aXeSdPjQW6zcz/yLf27lhsk79575gTe1aTtcAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkMGuTkNKRaGeMaGoWvUmlrTb3s8X/b43LWjU96YTFY2elZuZ7Vi5Yc+7f5XalJXr98xpSFVvws2o8Ca5jJK3/6o17zSqFEMr50wH63a8fdfb8KbbXDrv3beiZ04nGjWtWL3qTc7qeIem2jXv/l1YXLZyA3Pilta96UvveOidVu7Bd/6UlXvIzP39l5+0cs1W+XO9Utn+8ZYrYAAAMqCAAQDIgAIGACCDW/obcESckrQmaSxplFI6cTtWCgCAve52PAnrX6WULt6G/w8AAPsGv4IGACCDWy3gJOkfI+KbEfHYtb4hIh6LiJMRcbLXG93i4gAA2Btu9VfQv5BSOhcRhyQ9GRE/SCl99epvSCk9LulxSTp4cMp7USEAAHvMLV0Bp5TOTf5dlPS3kt59O1YKAIC9zi7giOhGxPQbH0v6ZUnP3q4VAwBgL7uVX0EflvS3EfHG/+cvU0r/cFvWCgCAPc4u4JTSS5J++jauCwAA+wYvQwIAIINdnYZUqVQ1NTVTOjc7M+ctMJWfGiNJW5vey6W2et5Uo2rdiml6xpuGNGp6k2PGA29yzNTUrJWrVr39VwxWrVyl7i1vlLzjpTf2JgaNo/x6nj77urWsdtM79+pasHKjNLZyUXgvsIhKYeWmO945tLW5YeV6Q3NyVss7ph94+4NWbn7B2+9T09NW7sWXz1q50+cWrdzBg3eVztRq268jV8AAAGRAAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkAEFDABABhQwAAAZUMAAAGSwq9OQxuOxVpbLT6pZX1u3ltfr961cq+1tlrkF7+eZ7pQ31ajf86bwRNG1cqOBN3GmGmHltja9yTjjobf/tvre8jaTd3wOB96EmyjapTMblwfWstpVb8JXLbx9UAy96USthre8dtubajQYeMdKpeqt5z2HD1q5qZmWlZs3pxOdXzxv5Y79xE9auR++8IKVazXLn0OStLxR/jE3pe0fN7kCBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMKGAAADKggAEAyIACBgAgg12dhlSphJqteumck5GkWsObrDK/4E0nOnr8gJXbWPOmGq0tm7svNaxYq+3ltja9iTqDgZfrds317HnHy+XeppVrmxNZkjHkq1J426Ra8aYFjc1pQfWKt55t89gcDr1z78BdD1i5h3/yp6xcrWrFNCq8SV0ra95Uo3e86xEr152es3JFccrKjYbeY8v6+lrpTFFsfy5wBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAa7Og2pVqvqroPTpXPtjjcNaTQ27154E1JWVpat3Na6t57VyiErVwlvCo87QSQq3mSclLzpRNWaN8FnZnrByi2uevt9sz+0cjPNbulMu+FN+CpG3rnQ6ZjTl6reNYF7rDQa3no+cP9PWrlm3dsPLz7/Ayt36HD5Y0WS7j5yzMq95YG3W7lLl7as3EsvPW/lFhdPW7nhsPw5m1La9mtcAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkMGuTkOq1ipaOFB+GkizXbWWt9XrW7nBwIppY80Lbq5vPy3jeuZnWlau8IbwaHn5kpVzJ9xUKt5+T8mbvlSvepNxir45zSq8CT7tdvn1bEZYy4qW+TN6xZuiNPY2ieo1b2La3fcctXK90aqVWzpz3sqtrXu5++57wMrNzM5aubUN78Hl29/5jpX7wQ+/a+Vqde/4rNfKT5eqVLY/h7gCBgAgAwoYAIAMKGAAADK4YQFHxKciYjEinr3qtoWIeDIinp/8O7+zqwkAwN5yM1fAfy7pfT9228ckfTml9KCkL08+BwAAN+mGBZxS+qqkyz928wckPTH5+AlJH7zN6wUAwJ7m/g34cErpjefFvybp8HbfGBGPRcTJiDi5se69LAgAgL3mlp+ElVJKkrZ9IWtK6fGU0omU0onuVPNWFwcAwJ7gFvCFiDgiSZN/F2/fKgEAsPe5BfxFSY9OPn5U0hduz+oAALA/3MzLkP5K0v+S9PaIOBsRvynpDyW9NyKel/SvJ58DAICbdMM3sU0pfXibL/3SbV4XAAD2Dd4JCwCADHZ1GlJUpHq3/KSaYfKmDKWaN1qlGJkjWSreRJZOx3sjscIcHbO1uWzluo3yk6wkqdXypjZt9Das3HDkTWQptn8y/3W1695+PzA7Z+Xm2jPlQyNvGlJh/oi+uu7tu1az/LQZSepOedN7KlVv361trVi54/fcbeUWFrxzqL3gHWOX17yXjD7z1D9Yuae+/k9Wbjhas3L1ujdpbbCxWT6Utn+c5goYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMdnUa0mg80qXly6VzY3M6UavtTRAZjqyYkryJM1VzilJ/q2flxuMtKzfjTOGRVAlzEs/Y2xEz5nSplXVvws3BeW95U21v8k9F5Se5DMbeRLFi7O27uWlvm3Q701auEt5DWc3MLZj7vN/3zr2DRw5Zueasd4z95V982sqdPXfKyqUwpgxJajTNCht7k88OHmiXztRq21/ncgUMAEAGFDAAABlQwAAAZEABAwCQAQUMAEAGFDAAABlQwAAAZEABAwCQAQUMAEAGFDAAABlQwAAAZEABAwCQAQUMAEAGuzoNSSlUjMpP/qmE93NCb8ubolSMveWNzQkbUZg5b1CNqjUvOJY3fWmr5001ajQbVm44GFu5SuHt927Lm7qVxt56qlr+HKrVvFO90+xYOXfCVz3KT3qSpOlpb1JXu+tNC+qtLlm5jfVVK3foyJyVe/qZb1q5c6+9YOU6M95xNjvrTZdyHwQ3Vjes3IH52dKZ6517XAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJDBrk5DiqioUZ8qnZuaKp+RpDNnzli5zU1vUkYledN7plveVJxI3s9PlYo3fanWMCeP9PpWrlNvWrlBz5vaVE3e/Wub69kfeFOihv1B6cz0lDctqFH1jml3slSz4e5z7xiLinlMj9atXLPmTXs6c+qUlXv2O09buQML01ZuZs7bfwsHvKlbzZa3vNMvn7dyr55fLp0ZDLc/z7kCBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMKGAAADKggAEAyIACBgAgg12dhlSr1jQ/P186Nxp5U2N65lSc4XWmV1xPq+5N9KhWvN0wGA+tXL1aWDlVvEkulWrdyhWFuR8a3vasypuME8mbZlVteNsztcpvz0rVW9Y4eZOz3GOz0/SmL7nnUL3dsnKDVW9i2sLUrJUbmY9lC21veW9/24NW7vSrP7JytbH3mFQdedtlquWd62c3N0tnimL7+8YVMAAAGVDAAABkcMMCjohPRcRiRDx71W0fj4hzEfH05L/37+xqAgCwt9zMFfCfS3rfNW7/05TSI5P/vnR7VwsAgL3thgWcUvqqpMu7sC4AAOwbt/I34I9ExDOTX1GXf2ozAAD7mFvAn5D0gKRHJJ2X9MfbfWNEPBYRJyPi5Pq695RxAAD2GquAU0oXUkrjlFIh6c8kvfs63/t4SulESunE1JT3mjsAAPYaq4Aj4shVn35I0rPbfS8AAHizG759TET8laT3SLorIs5K+n1J74mIRyQlSack/dYOriMAAHvODQs4pfTha9z8yR1YFwAA9g3eCQsAgAx2dRjDaDzS0vKl8rmR+Wb3Ne/ni8Ga90byo/6Wlaul8m/wLUnTnRkr16x7b3y+vtm3cpWq9wb7Cm8QQKvlDR5wT4Zi4OXCHFLRN06H1XVveMChw3dbubF3yqo13bVytZp3jA0Kb0VfX1mzcm+557iVm+96QxU6TW97jsxzLw56J0NR8d5qIirecT1z72Ert7xS/pU89fr2j0dcAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkMGuTkNKKWk0GpXOtTtNa3mVJe/ni62t8usoSZG8SSBTHS/XmW1bubGxDyRp+cKSlTty8JiVa9e9wzPG3tSm8aD8pBNJCnPaU2/kTaU6dt+DpTMPLxy0llWpevug3e1YueXVZSu3srZq5b71rWes3PLyRSt3/vCclTt+11utXLs7b+Wq9bByjaY3iezikvcYuN5bsXLVutcNBw9Nl87UmIYEAMCdhQIGACADChgAgAwoYAAAMqCAAQDIgAIGACADChgAgAwoYAAAMqCAAQDIgAIGACADChgAgAwoYAAAMqCAAQDIYJenIRXa2toqnRsX3qSMtbV1K9dsetNtmk1vatMobVq5xcuvWbmNdW9a0NKqNw2p3Z2ycp2Fe6zccDC0ckXyfh6tKFm5asM7zrrd8hNZDh/2tuWSOZ3o3PlzVu7FUy9YuZfPvGzlFl9ftHLTU96+e+HMc1buzBlvPeuVupVrd7xJXZ2uNw1pffN1KzdKG1Zutb/mLc8YJJfS9o8PXAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJDBrk5DGo8LrRsTiup9b6JH3Zw202qHlWs0vc05GniTR5aWLlq5tVVvGlJR8dbz/EVvMs787EEr12p705fWl3pWrtPyJsCMxmMr99KLz5fOXHzdO1Y2et60mVfOnbJyq+srVq7f8yafNereMa2aN3FrY+BNl1pc8e5ff8s7pqdmvAl0Cwc6Vq7V9s6hMB+TZE4wS3KWxzQkAADuKBQwAAAZUMAAAGRAAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkAEFDABABrs6DalSqajVapfOVavuanoTNiqVkZWre8OXVJhTcare3VNReMvbHGxauZUVb6LO/NRrVu7IgSNWrj/0JquMh96kmuHQ2w+zs+WndW2tWYtSd8qbbnP8yCErd/rclpUbjbwJZncfucfL3Ttn5VbXvWlIL/eWrNx44G3PxrQVU2p458KoYj54mpJ36mlufrZ0pnqdB2qugAEAyIACBgAgAwoYAIAMbljAEXE8Ir4SEd+PiO9FxEcnty9ExJMR8fzk3/mdX10AAPaGm7kCHkn63ZTSw5J+VtJvR8TDkj4m6csppQclfXnyOQAAuAk3LOCU0vmU0rcmH69Jek7SUUkfkPTE5NuekPTBnVpJAAD2mlKv74mIt0p6l6SnJB1OKZ2ffOk1SYe3yTwm6TFJmp5puusJAMCectNPwoqIKUmfk/Q7KaXVq7+WUkqS0rVyKaXHU0onUkonOt3dfa0XAAB3qpsq4Iio60r5fjql9PnJzRci4sjk60ckLe7MKgIAsPfczLOgQ9InJT2XUvqTq770RUmPTj5+VNIXbv/qAQCwN93M34B/XtJvSPpuRDw9ue33JP2hpM9GxG9KekXSr+3MKgIAsPfcsIBTSl+TtN0brf7S7V0dAAD2B94JCwCADHZ1GpKSlK75XOnrW13xpvCo4o28aHe8zTIcGndO0sjMbfV6Vm5cDK1cxfx5rVnznv2+9PolKzfX7Fq5SnjTkFbXvAkwtfC259LF10tnZqa88TYry5etXGH+aH/8yDErN+h758Lc1JSVO3rYm4Z05G7v2Fxb8u5fkjcNaW7Oe8loxMDLyTv3IryRcFHzpmeNRs5+2P6+cQUMAEAGFDAAABlQwAAAZEABAwCQAQUMAEAGFDAAABlQwAAAZEABAwCQAQUMAEAGFDAAABlQwAAAZEABAwCQAQUMAEAGuzoNKSoVtdud8sFUt5aXwpv6U696P5cMvEEg2tzwpun0et4Cx+ORles2Z63cQw/8MytXGXn7oR7edKmKNyBFreZdVq5W8e5fjMpP+dra8CaKRdWbZJW8QWSqmg9Jx47ca+WWll61cotn16xcd7Zt5Vp1b1rQPXd7U5tmut6xORp404mK5N2/ZtM7Pqs17zhbXVstnSmuMwKQK2AAADKggAEAyIACBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMKGAAADLY3WlIIVUr5adlNBredJvV1RUrt1V4Ez16m15ufcMbHVMkbxJIVL3pUkfmjli5t9/7oJVbWVq2cudePWPlWuZklUajZeVC5vglYzXNwWC6a37eyr2+dNnKbQ76Vm5utmvl1la8iWJLy94Es8vr3rmeqt5jy/SMt//6PW8/jAfeVKN2xzuH2m1vutRo7O33JK+LtsMVMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGezqNKRiXGhjfaN0bjDwJlfInDYTydssw4E3KaPf9yaIFMZkKUkqCu/nrtHYu3+XLl20cr1+z8o16k1veQNvZFDUvAk3St7xWa+XH4fUmZ62llUxt2W3M2PlGm1vIlW97Z0Lg5p3LrRqU1auWvfO9dkpb7t0pxas3IuLz1u5asW7f7Wmt//GyZvsNhh5056KZNy/tP3jJlfAAABkQAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGVDAAABksKvTkCLCmuTS73tTakZeTIO+N31paC6v0fAmnaxtetOCCm+okV5b8aYaVc96h9mxu49YudkZb1LNhYuvW7nzyxesXNXcD0cPHi6dme50rGVFjKzckdl5K9eqecfKuQ1v3102J63NjbwpUW1zgtl9R+63ct2mNwXrzEsvWbnOTMvKVWveZLBer/x0PcmftBZhXLPG9veNK2AAADKggAEAyIACBgAggxsWcEQcj4ivRMT3I+J7EfHRye0fj4hzEfH05L/37/zqAgCwN9zMMx5Gkn43pfStiJiW9M2IeHLytT9NKf3Rzq0eAAB70w0LOKV0XtL5ycdrEfGcpKM7vWIAAOxlpf4GHBFvlfQuSU9NbvpIRDwTEZ+KiGu+7iAiHouIkxFxcnPTe8o/AAB7zU0XcERMSfqcpN9JKa1K+oSkByQ9oitXyH98rVxK6fGU0omU0olOx3u9KwAAe81NFXBE1HWlfD+dUvq8JKWULqSUximlQtKfSXr3zq0mAAB7y808CzokfVLScymlP7nq9qvfpuhDkp69/asHAMDedDPPgv55Sb8h6bsR8fTktt+T9OGIeERSknRK0m/tyBoCALAH3cyzoL8m6VpvZvml2786AADsD7wTFgAAGez6NKRavfwiOx1vus3S0nkrNx56kzkG5jSkqOzqbvAmekha21q3cmcvvmrlDhyYs3Kzcwes3NTQO84WF1es3Naql6up/IHWPFx+gpIkVcbeNKTWyDum+2Pv2FzpvWblirE3TWej572kstn0pigVxaaVu3DBm2DWbHn7r9n0piF1Ot526fe3rNzIPK4rRflpVnHNXyBP/n/WWgAAgFtCAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkAEFDABABhQwAAAZUMAAAGRAAQMAkAEFDABABhQwAAAZUMAAAGSwq2N4ilSo3+uVzvW2xtbyqhVvwsZw7I01Ksbeeo5H3mSVpGTliqKwcqORt13GRd3KvXj6JSu3ubFm5eYX7rJyD/3Ew1bu1TOnrFw1lZ/kMndowVtWz5uANVvxpuJU1LByB1e9c+jMaW9iWsU8h2ZnvIlbqxtLXm5t1cpVq141FOY0q37Pe+wcDLz9MDRzG5vlpy+Ni+3vG1fAAABkQAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGVDAAABkQAEDAJABBQwAQAYUMAAAGVDAAABksLvTkMaF1jc2Sue2Ns1JGX0v1x+UnzYjSaORN2EjRVg5cxiSRiNvu1TM5Sl5wbVNbxJPf9j3ltfzcgfn77FyjXrbykWUn/xzcd2binPfPd59O3D4uJW7uLpp5QYve9OQ5me89ax5w57Uqk1buY11bxrS2qY59We9/NQ6SWo3vXO90fSqyJ3QVhTeY+5oVP7+Xe/hjytgAAAyoIABAMiAAgYAIAMKGACADChgAAAyoIABAMiAAgYAIAMKGACADChgAAAyoIABAMiAAgYAIAMKGACADChgAAAy2N1pSJL64/LTOXrmxIutoTeZo0jeZqlUvQkbg+RNLOkPvAkwyZzaFDLX05wyVG/UrVwK73hZ2bhg5Uaj8hO+JGlcePuvO11+u7y2tGwtK+reVJxXLp2zcpt975pg5K2mmq1ZKxdVb4Eba+b0Hnnjl0b9LSvX31yxcjVzsJvM+5fkLXCcqlZuVBjHZ9p+HbkCBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAMKGAAADKggAEAyIACBgAgg12dhjQeF1pZKz9FZGPDmzwy7Ht3r2ZO5qhWveWNkjchJSru7vOWZw4e0WDoLS+Z05em2w0r12x7y6u1Nq3cdLtp5Trd8vu96g1/0ebAm4v+PXoAAAaYSURBVBC1urxu5YqRd+5124esXH/oTaRaW79o5apr3jVPSt5kt6q545t1L1eMvXN9c3Ns5RTeem72vf2+1SvfReNi+8cVroABAMiAAgYAIAMKGACADG5YwBHRioivR8R3IuJ7EfEHk9vvi4inIuKFiPjriPD+8AYAwD50M1fAfUm/mFL6aUmPSHpfRPyspP8i6U9TSm+TtCTpN3duNQEA2FtuWMDpijee0lif/Jck/aKkv5nc/oSkD+7IGgIAsAfd1N+AI6IaEU9LWpT0pKQXJS2nlEaTbzkr6eg22cci4mREnOz3Rtf6FgAA9p2bKuCU0jil9IikY5LeLemhm11ASunxlNKJlNKJZmtXX3YMAMAdq9SzoFNKy5K+IunnJM1FxBuNekzSudu8bgAA7Fk38yzogxExN/m4Lem9kp7TlSL+1cm3PSrpCzu1kgAA7DU38zvhI5KeiIiqrhT2Z1NKfx8R35f0mYj4T5K+LemTO7ieAADsKTcs4JTSM5LedY3bX9KVvwcDAICSeCcsAAAy2OVpSEkrS/3SuaLwxvAMvCFKGoU3FadR9yZspKp3/6Li/fxUb3hvWmYOSFHPnDzijl8KM9ftepN4Dt89beWi4q1nw9gR/UH5806SlLwpNTPzXSt3+dKWlXt9yXsOaLXqTaRKyXuMCHM60eaGN3ErwjzGal41DAbe/ht5m1Pj5N2/3sB7SezAyBXF9pOsuAIGACADChgAgAwoYAAAMqCAAQDIgAIGACADChgAgAwoYAAAMqCAAQDIgAIGACADChgAgAwoYAAAMqCAAQDIgAIGACCDSGn7SQ23fWERr0t6ZZsv3yXp4q6tzP8/2C5vxja5NrbLtbFdro3t8mY7sU3eklI6eK0v7GoBX09EnEwpnci9HncatsubsU2uje1ybWyXa2O7vNlubxN+BQ0AQAYUMAAAGdxJBfx47hW4Q7Fd3oxtcm1sl2tju1wb2+XNdnWb3DF/AwYAYD+5k66AAQDYNyhgAAAyyF7AEfG+iPhhRLwQER/LvT53iog4FRHfjYinI+Jk7vXJJSI+FRGLEfHsVbctRMSTEfH85N/5nOuYwzbb5eMRcW5yzDwdEe/PuY67LSKOR8RXIuL7EfG9iPjo5PZ9fbxcZ7vs9+OlFRFfj4jvTLbLH0xuvy8inpp00l9HRGPH1iHn34AjoirpR5LeK+mspG9I+nBK6fvZVuoOERGnJJ1IKe3rF8pHxL+UtC7pL1JK75jc9l8lXU4p/eHkh7b5lNJ/yLmeu22b7fJxSesppT/KuW65RMQRSUdSSt+KiGlJ35T0QUn/Tvv4eLnOdvk17e/jJSR1U0rrEVGX9DVJH5X07yV9PqX0mYj4H5K+k1L6xE6sQ+4r4HdLeiGl9FJKaSDpM5I+kHmdcAdJKX1V0uUfu/kDkp6YfPyErjyY7CvbbJd9LaV0PqX0rcnHa5Kek3RU+/x4uc522dfSFeuTT+uT/5KkX5T0N5Pbd/R4yV3ARyWduerzs+LAeEOS9I8R8c2IeCz3ytxhDqeUzk8+fk3S4Zwrc4f5SEQ8M/kV9b76VevVIuKtkt4l6SlxvPwfP7ZdpH1+vERENSKelrQo6UlJL0paTimNJt+yo52Uu4CxvV9IKf2MpF+R9NuTXznix6Qrf0PhtXRXfELSA5IekXRe0h/nXZ08ImJK0uck/U5KafXqr+3n4+Ua22XfHy8ppXFK6RFJx3TlN7IP7ebycxfwOUnHr/r82OS2fS+ldG7y76Kkv9WVgwNXXJj8XeuNv28tZl6fO0JK6cLkAaWQ9Gfah8fM5G95n5P06ZTS5yc37/vj5VrbhePl/0opLUv6iqSfkzQXEbXJl3a0k3IX8DckPTh51llD0q9L+mLmdcouIrqTJ0soIrqSflnSs9dP7StflPTo5ONHJX0h47rcMd4omYkPaZ8dM5Mn1XxS0nMppT+56kv7+njZbrtwvMTBiJibfNzWlScDP6crRfyrk2/b0eMl+zthTZ76/t8kVSV9KqX0n7Ou0B0gIu7XlateSapJ+sv9ul0i4q8kvUdXxoRdkPT7kv5O0mcl3asr4y1/LaW0r56QtM12eY+u/DoxSTol6beu+tvnnhcRvyDpnyR9V1Ixufn3dOXvnfv2eLnOdvmw9vfx8lO68iSrqq5cjH42pfQfJ4+/n5G0IOnbkv5tSqm/I+uQu4ABANiPcv8KGgCAfYkCBgAgAwoYAIAMKGAAADKggAEAyIACBgAgAwoYAIAM/jdq//78ON9lbQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6xSM8mX78gO"
      },
      "source": [
        "## More Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSJw3YqW9JGf"
      },
      "source": [
        "# normalize each image between values of 0-1 using the z-score normalization equation\n",
        "\n",
        "def normalize(img):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args: a numpy array with pixel values ranging from 0-255\n",
        "  Returns: a normalized numpy array with values ranging between 0-1\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  min = np.min(img)\n",
        "  max = np.max(img)\n",
        "  normalized = (img - min) / (max - min) \n",
        "\n",
        "  normalized = tf.cast(normalized, dtype = tf.float32)\n",
        "\n",
        "  return normalized\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du8tIc5eJqf0"
      },
      "source": [
        "# labels are integers ranging from 0-9 corresponding to indexes for a particular label in label dict\n",
        "\n",
        "def one_hot_encode(label):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args: an integer label ranging from 0-9\n",
        "\n",
        "  Returns: a one-hot encoded version of the label with a '1' \n",
        "           at the corresponding index (e.g the label '3' will be one-hot-encoded\n",
        "           into a tensor of shape (1,10) with zeroes at every index except the 3rd)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  encoded = tf.one_hot(label, 10)\n",
        "  return encoded\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRFr9Bjd_hYe"
      },
      "source": [
        "def preprocess(filename):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args: a filename containing a batch directory as well as a sub directory of batches\n",
        "\n",
        "  Returns: a preprocessed dataset in the form of of normalized images (batch size, 32, 32, 3) and \n",
        "           one-hot-encoded labels of shape (1, 10).\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  batches = get_batches(filename)\n",
        "  all_data = []\n",
        "\n",
        "  for batch in batches:\n",
        "    all_data.append(unpickle(\"/content/cifar-10-batches-py\"+\"/\"+batch))\n",
        "\n",
        "  data = []\n",
        "\n",
        "    \n",
        "  for i, batch in enumerate(all_data):\n",
        "    \n",
        "    images, labels = shape(batch)\n",
        "    images = np.array([normalize(x) for x in images])\n",
        "    labels = [one_hot_encode(x) for x in labels]\n",
        "    data.append((images,labels))\n",
        "\n",
        "  return data\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhEfLCPlWdSR"
      },
      "source": [
        "data = preprocess(\"/content/cifar-10-batches-py\")"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKZbBaUjamc_"
      },
      "source": [
        "Right now, batches are in separate lists. To make training faster we want to convert the\n",
        "data to a tensorflow dataset and have it prefetched. After that we can rebatch the dataset into batches of 10000 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuREtZEVdypA"
      },
      "source": [
        "def one_list(list):\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  Args: a list containing a different batch at each index\n",
        "\n",
        "  Returns: 2 lists: Images and Labels\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for i, batch in enumerate(list):\n",
        "    for image in batch[0]:\n",
        "      images.append(image)\n",
        "    for label in batch[1]:\n",
        "      labels.append(label)\n",
        "\n",
        "  return images, labels\n",
        "\n",
        "def convert_to_datasets(data):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args: a list with sublists of batches. \n",
        "        batch[0] = images\n",
        "        batch[1] = label\n",
        "\n",
        "  Returns: a tuple containing a prefetched and batched tensorflow dataset (train and validation)\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  if len(data)> 1:\n",
        "    images, labels = one_list(data)\n",
        "  else:\n",
        "    images = data[0][0]\n",
        "    labels = data[0][1]\n",
        "\n",
        "  split = int(len(images) * 0.8)\n",
        "\n",
        "  train_images = images[:split]\n",
        "  val_images = images[-split:]\n",
        "  train_labels = labels[:split]\n",
        "  val_labels = labels[-split:]\n",
        "\n",
        "\n",
        "\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "  train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        " \n",
        "\n",
        "  return train_dataset, val_dataset"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ9xXOQvfVL-"
      },
      "source": [
        "temp_images, labels = one_list(data)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PaY-m-yGQmx",
        "outputId": "f074eb97-5f07-4207-8335-2158ebe4eb76"
      },
      "source": [
        "temp_images[0].shape"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYtrsr5FfnVs"
      },
      "source": [
        "train_dataset, val_dataset = convert_to_datasets(data)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcvp4ubkhOs9",
        "outputId": "2373a214-f32b-433c-eebb-8c4b5a21685c"
      },
      "source": [
        "train_dataset, val_dataset"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: ((None, 32, 32, 3), (None, 10)), types: (tf.float32, tf.float32)>,\n",
              " <PrefetchDataset shapes: ((None, 32, 32, 3), (None, 10)), types: (tf.float32, tf.float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL-27OdwNN6t"
      },
      "source": [
        "## My Steps\n",
        "\n",
        "1. Build a basic residual block function that will compute convolutions and add the resultant tensor with that of the original\n",
        "2. Build an identity block function that will "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGuIWjPoEC4j"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "data_augmentation = Sequential([\n",
        "    preprocessing.RandomFlip(\"horizontal\")\n",
        "    \n",
        "    #preprocessing.Rescaling(1/255.0) #don't need this since already normalized\n",
        "], name = 'data_augmentation')"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzfEcQ0sEDmd"
      },
      "source": [
        "# First define the identity block, where the dimension des not change, but the depth does.\n",
        "# Following the stucture of the ResNet50 model\n",
        "\n",
        "def identity(input, filters):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args:  \n",
        "    input: the input passed from a previous layer (using the tensorflow functional API)\n",
        "    filters: a tuple containing the respective number of filters being applied in the convolutions\n",
        "\n",
        "  Returns: an output 'x' of which will be passed to another layers within the model\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  skip = input\n",
        "  filter1, filter2 = filters\n",
        "\n",
        "  #first block\n",
        "  x = Conv2D(filter1, kernel_size = (1,1), strides = (1,1), padding = 'valid', kernel_regularizer = regularizers.l2(0.001))(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #second block (size is kept the same with padding = 'same')\n",
        "  x = Conv2D(filter1, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_regularizer = regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #third block \n",
        "  x = Conv2D(filter2, kernel_size= (1,1), strides = (1,1), padding = 'valid', kernel_regularizer = regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  #add the input\n",
        "  x = Add()([x, skip])\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  return x\n"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U37BWcnEHlB"
      },
      "source": [
        "def res_conv(input, strides, filters):\n",
        "\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    \n",
        "    input: the input passed from a previous layer\n",
        "    strides: how far the filter moves before being applied again \n",
        "    filters: a tuple containing the number of conv filters being applied to the input\n",
        "  \n",
        "\n",
        "  Returns:\n",
        "\n",
        "    an output with reduced dimensionality of the input shape /2 (following the ResNet50 structure)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  skip = input\n",
        "  filter1, filter2 = filters\n",
        "\n",
        "  #first block\n",
        "  x = Conv2D(filter1, kernel_size = (1,1), strides = (strides, strides), padding = 'valid', kernel_regularizer=regularizers.l2(0.001))(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #second block\n",
        "  x = Conv2D(filter1, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_regularizer= regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #third block\n",
        "  x = Conv2D(filter2, kernel_size = (1,1), strides = (1,1), padding = 'valid', kernel_regularizer = regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  \n",
        "  #converting the input tensor to match the dimensionality of the newly changed x (due to changing the strides)\n",
        "  skip = Conv2D(filter2, kernel_size = (1,1), strides = (strides, strides), padding = 'valid', kernel_regularizer = regularizers.l2(0.001))(skip)\n",
        "  skip = BatchNormalization()(skip)\n",
        "\n",
        "  #add\n",
        "  x = Add()([x, skip])\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  return x\n"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D7LRA23EOUW"
      },
      "source": [
        "# finally building the ResNet Model!!\n",
        "\n",
        "from keras.layers import Input, AveragePooling2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import activations, regularizers\n",
        "\n",
        "\n",
        "def resnet50():\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args: None\n",
        "\n",
        "  Returns: the ResNet50 tensorflow model\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  input_image = Input(shape = (32,32,3)) #the way images in CIFAR dataset are stuctured\n",
        "  resize = UpSampling2D(size=(7,7))(input_image)\n",
        "  x = data_augmentation(resize)\n",
        "  x = ZeroPadding2D(padding = (3,3))(x) #to preserve original input size\n",
        "\n",
        "  #step 1: maxpooling (refer to model summary of ResNet50)\n",
        "\n",
        "  #images are scaled to 256x256\n",
        "  x = Conv2D(64, kernel_size = (7,7), strides = (2,2))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "  x = MaxPooling2D((3,3), strides = (2,2))(x)\n",
        "\n",
        "  #step 2:\n",
        "\n",
        "  x = res_conv(x, strides = 1, filters = (64, 256))\n",
        "  x = identity(x, filters=(64, 256))\n",
        "  x = identity(x, filters = (64,256))\n",
        "\n",
        "  #step 3:\n",
        "\n",
        "  x = res_conv(x, strides = 2, filters = (128, 512))\n",
        "  x = identity(x, filters = (128, 512))\n",
        "  x = identity(x, filters = (128, 512))\n",
        "  x = identity(x, filters = (128, 512))\n",
        "\n",
        "  #step 4\n",
        "\n",
        "  x = res_conv(x, strides = 2, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "\n",
        "  #step 5\n",
        "\n",
        "  x = res_conv(x, strides = 2, filters = (512, 2048))\n",
        "  x = identity(x, filters = (512, 2048))\n",
        "  x = identity(x, filters = (512, 2048))\n",
        "\n",
        "  #model concludes with average pooling and dense connection\n",
        "\n",
        "  x = AveragePooling2D((2,2), padding = 'same')(x)\n",
        "\n",
        "  #add a flatten layer as dense required this input shape\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(10, activation = 'softmax', kernel_initializer = tf.keras.initializers.he_normal)(x)\n",
        "\n",
        "  model = Model(inputs = input_image, outputs = x, name = 'Resnet50')\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwBvZNClFDKE"
      },
      "source": [
        "class EarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
        "    \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current = logs.get(\"loss\")\n",
        "        if np.less(current, self.best):\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            # Record the best weights if current results is better (less).\n",
        "            self.best_weights = self.model.get_weights()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                print(\"Restoring model weights from the end of the best epoch.\")\n",
        "                self.model.set_weights(self.best_weights)\n",
        "\n",
        "earlyStopping = EarlyStoppingAtMinLoss()"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DfdDy56ERqp",
        "outputId": "90310280-b42d-4b93-b1d9-b8396ba8c7f9"
      },
      "source": [
        "model = resnet50()\n",
        "model.summary()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 3)  0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.image.random_flip_left_right (None, 224, 224, 3)  0           up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 230, 230, 3)  0           tf.image.random_flip_left_right_3\n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 112, 112, 64) 9472        zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 112, 112, 64) 256         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 112, 112, 64) 0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 55, 55, 64)   4160        max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 55, 55, 64)   256         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 55, 55, 64)   0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 55, 55, 64)   36928       activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 55, 55, 64)   256         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 55, 55, 64)   0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 55, 55, 256)  16640       activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 55, 55, 256)  16640       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 55, 55, 256)  1024        conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 55, 55, 256)  1024        conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 55, 55, 256)  0           batch_normalization_162[0][0]    \n",
            "                                                                 batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 55, 55, 256)  0           add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 55, 55, 64)   16448       activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 55, 55, 64)   256         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 55, 55, 64)   0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 55, 55, 64)   36928       activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 55, 55, 64)   256         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 55, 55, 64)   0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 55, 55, 256)  16640       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 55, 55, 256)  1024        conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 55, 55, 256)  0           batch_normalization_166[0][0]    \n",
            "                                                                 activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 55, 55, 256)  0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 55, 55, 64)   16448       activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 55, 55, 64)   256         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 55, 55, 64)   0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 55, 55, 64)   36928       activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 55, 55, 64)   256         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 55, 55, 64)   0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 55, 55, 256)  16640       activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 55, 55, 256)  1024        conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 55, 55, 256)  0           batch_normalization_169[0][0]    \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 55, 55, 256)  0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 28, 28, 128)  32896       activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 28, 28, 128)  512         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 28, 28, 128)  0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 28, 28, 128)  147584      activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 28, 28, 128)  512         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 28, 28, 128)  0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 28, 28, 512)  66048       activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 28, 28, 512)  131584      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 28, 28, 512)  2048        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 28, 28, 512)  2048        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 28, 28, 512)  0           batch_normalization_172[0][0]    \n",
            "                                                                 batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 28, 28, 512)  0           add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 28, 28, 128)  65664       activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 28, 28, 128)  512         conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 28, 28, 128)  0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 28, 28, 128)  147584      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 28, 28, 128)  512         conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 28, 28, 128)  0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 28, 28, 512)  66048       activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 28, 28, 512)  2048        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 28, 28, 512)  0           batch_normalization_176[0][0]    \n",
            "                                                                 activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 28, 28, 512)  0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 28, 28, 128)  65664       activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 28, 28, 128)  512         conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 28, 28, 128)  0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 28, 28, 128)  147584      activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 28, 28, 128)  512         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 28, 28, 128)  0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 28, 28, 512)  66048       activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 28, 28, 512)  2048        conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 28, 28, 512)  0           batch_normalization_179[0][0]    \n",
            "                                                                 activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 28, 28, 512)  0           add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 28, 28, 128)  65664       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 28, 28, 128)  512         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 28, 28, 128)  0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 28, 28, 128)  147584      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 28, 28, 128)  512         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 28, 28, 128)  0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 28, 28, 512)  66048       activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 28, 28, 512)  2048        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 28, 28, 512)  0           batch_normalization_182[0][0]    \n",
            "                                                                 activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 28, 28, 512)  0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 14, 14, 256)  131328      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 14, 14, 256)  1024        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 14, 14, 256)  0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 14, 14, 256)  590080      activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 14, 14, 256)  1024        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 14, 14, 256)  0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 14, 14, 1024) 263168      activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 14, 14, 1024) 525312      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 14, 14, 1024) 4096        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 14, 14, 1024) 4096        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_185[0][0]    \n",
            "                                                                 batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 14, 14, 1024) 0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 14, 14, 256)  262400      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 14, 14, 256)  1024        conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 14, 14, 256)  0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 14, 14, 256)  590080      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 14, 14, 256)  1024        conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 14, 14, 256)  0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 14, 14, 1024) 263168      activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 14, 14, 1024) 4096        conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_189[0][0]    \n",
            "                                                                 activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 14, 14, 1024) 0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 14, 14, 256)  262400      activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 14, 14, 256)  1024        conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 14, 14, 256)  0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 14, 14, 256)  590080      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 14, 14, 256)  1024        conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 14, 14, 256)  0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 14, 14, 1024) 263168      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 14, 14, 1024) 4096        conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_192[0][0]    \n",
            "                                                                 activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 14, 14, 1024) 0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 14, 14, 256)  262400      activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 14, 14, 256)  1024        conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 14, 14, 256)  0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 14, 14, 256)  590080      activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 14, 14, 256)  1024        conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 14, 14, 256)  0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 14, 14, 1024) 263168      activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 14, 14, 1024) 4096        conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_195[0][0]    \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 14, 14, 1024) 0           add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 14, 14, 256)  262400      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 14, 14, 256)  1024        conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 14, 14, 256)  0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 14, 14, 256)  590080      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 14, 14, 256)  1024        conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 14, 14, 256)  0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 14, 14, 1024) 263168      activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 14, 14, 1024) 4096        conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_198[0][0]    \n",
            "                                                                 activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 14, 14, 1024) 0           add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 14, 14, 256)  262400      activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 14, 14, 256)  1024        conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 14, 14, 256)  0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 14, 14, 256)  590080      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 14, 14, 256)  1024        conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 14, 14, 256)  0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 14, 14, 1024) 263168      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 14, 14, 1024) 4096        conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_201[0][0]    \n",
            "                                                                 activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 14, 14, 1024) 0           add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 7, 7, 512)    524800      activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 7, 7, 512)    2048        conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 7, 7, 512)    0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 7, 7, 512)    2359808     activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 7, 7, 512)    2048        conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 7, 7, 512)    0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 7, 7, 2048)   2099200     activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 7, 7, 2048)   8192        conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 7, 7, 2048)   8192        conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_204[0][0]    \n",
            "                                                                 batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 7, 7, 2048)   0           add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 7, 7, 512)    1049088     activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 7, 7, 512)    2048        conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 7, 7, 512)    0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 7, 7, 512)    2359808     activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 7, 7, 512)    2048        conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 7, 7, 512)    0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 7, 7, 2048)   8192        conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_208[0][0]    \n",
            "                                                                 activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 7, 7, 2048)   0           add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 7, 7, 512)    1049088     activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 7, 7, 512)    2048        conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 7, 7, 512)    0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 7, 7, 512)    2359808     activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 7, 7, 512)    2048        conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 7, 7, 512)    0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 7, 7, 2048)   8192        conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_211[0][0]    \n",
            "                                                                 activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 7, 7, 2048)   0           add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 4, 4, 2048)   0           activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 32768)        0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           327690      flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,915,402\n",
            "Trainable params: 23,862,282\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xzpjwLtEcdZ"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\n",
        "             optimizer = tf.keras.optimizers.Adam(), \n",
        "             metrics = ['accuracy'])"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrx4XJ88FN6g",
        "outputId": "195e3e6e-c019-4660-f1c3-e4bf2508d356"
      },
      "source": [
        "model_history = model.fit(train_dataset, steps_per_epoch = int(len(train_dataset)*0.1), \n",
        "                          validation_data = val_dataset, \n",
        "                          validation_steps = int(len(val_dataset)*0.1) ,\n",
        "                          epochs = 10, \n",
        "                          callbacks = [earlyStopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1230/1500 [=======================>......] - ETA: 1:34:42 - loss: 16.2579 - accuracy: 0.2980"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-_Uy2s0FvaL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}